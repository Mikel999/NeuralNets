{"cells":[{"cell_type":"markdown","metadata":{"id":"M-AmTvfK5MWC"},"source":["# Variational AutoEncoder\n"]},{"cell_type":"markdown","metadata":{"id":"Ld4KMnpP5MWG"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_rOE-Oz5MWG"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","metadata":{"id":"qSnKh2Fm5MWI"},"source":["## Create a sampling layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JNUloWtZ5MWI"},"outputs":[],"source":["\n","class Sampling(layers.Layer):\n","    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"]},{"cell_type":"markdown","metadata":{"id":"i7z55Vwq5MWJ"},"source":["## Build the encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyRbKk9g5MWJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654189300100,"user_tz":-120,"elapsed":243,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"64b2680a-3eeb-489d-d569-0e41ff70e6c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 1, 501)]     0           []                               \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 1, 32)        48128       ['input_5[0][0]']                \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 1, 64)        6208        ['conv1d_4[0][0]']               \n","                                                                                                  \n"," flatten_2 (Flatten)            (None, 64)           0           ['conv1d_5[0][0]']               \n","                                                                                                  \n"," dense_4 (Dense)                (None, 16)           1040        ['flatten_2[0][0]']              \n","                                                                                                  \n"," z_mean (Dense)                 (None, 2)            34          ['dense_4[0][0]']                \n","                                                                                                  \n"," z_log_var (Dense)              (None, 2)            34          ['dense_4[0][0]']                \n","                                                                                                  \n"," sampling_2 (Sampling)          (None, 2)            0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 55,444\n","Trainable params: 55,444\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["latent_dim = 2\n","\n","encoder_inputs = keras.Input(shape=(1,501))\n","x = layers.Conv1D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n","x = layers.Conv1D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(16, activation=\"relu\")(x)\n","z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n","z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n","z = Sampling()([z_mean, z_log_var])\n","encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n","encoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"9Rcqf4MQ5MWK"},"source":["## Build the decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SV2tNIC-5MWL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654189302364,"user_tz":-120,"elapsed":593,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"202969b5-69a9-4055-d25a-839792f346cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 2)]               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1503)              4509      \n","                                                                 \n"," reshape_4 (Reshape)         (None, 501, 3)            0         \n","                                                                 \n"," conv1d_transpose_6 (Conv1DT  (None, 501, 64)          640       \n"," ranspose)                                                       \n","                                                                 \n"," conv1d_transpose_7 (Conv1DT  (None, 501, 32)          6176      \n"," ranspose)                                                       \n","                                                                 \n"," conv1d_transpose_8 (Conv1DT  (None, 501, 1)           97        \n"," ranspose)                                                       \n","                                                                 \n"," reshape_5 (Reshape)         (None, 1, 501)            0         \n","                                                                 \n","=================================================================\n","Total params: 11,422\n","Trainable params: 11,422\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["latent_inputs = keras.Input(shape=(latent_dim,))\n","x = layers.Dense(501 * 3, activation=\"relu\")(latent_inputs)\n","x = layers.Reshape((501, 3))(x)\n","x = layers.Conv1DTranspose(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n","x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n","decoder_outputs = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n","decoder_outputs = layers.Reshape((1,501))(decoder_outputs)\n","decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n","decoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"WgLxx9Tm5MWM"},"source":["## Define the VAE as a `Model` with a custom `train_step`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_tySNx75MWM"},"outputs":[],"source":["class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss\"\n","        )\n","        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            reconstruction_loss = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.binary_crossentropy(data, reconstruction)\n","                )\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"1NLMACkV5MWN"},"source":["## Train the VAE"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sd6rTVzD7W7k","executionInfo":{"status":"ok","timestamp":1654180457246,"user_tz":-120,"elapsed":19552,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"e1229273-33f0-4221-8804-a8a381e7ab8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["movements=np.load('/content/drive/MyDrive/Colab Notebooks/small_train.npy')\n","movements.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXvhEkxQ6Qa9","executionInfo":{"status":"ok","timestamp":1654189017280,"user_tz":-120,"elapsed":1190,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"ddeab3c8-63cb-43a3-ce4a-9ba9bbd92bcd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 501)"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","def sci_minmax(X,input_minmax_scaler=None):\n","        if input_minmax_scaler is None:\n","            input_minmax_scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n","        return (input_minmax_scaler.fit_transform(X), input_minmax_scaler)\n","(movements, input_minmax_scaler) = sci_minmax(movements)"],"metadata":{"id":"rgHk1i6WUoPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOFWWRA35MWN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654190543059,"user_tz":-120,"elapsed":1164883,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"b278fd3e-d3e2-49ce-c2c2-40a2434e035c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","391/391 [==============================] - 78s 193ms/step - loss: 50.1302 - reconstruction_loss: 37.4719 - kl_loss: 0.1233\n","Epoch 2/15\n","391/391 [==============================] - 75s 192ms/step - loss: 28.6315 - reconstruction_loss: 28.4473 - kl_loss: 1.5658e-04\n","Epoch 3/15\n","391/391 [==============================] - 76s 195ms/step - loss: 28.2298 - reconstruction_loss: 28.1821 - kl_loss: 1.1883e-04\n","Epoch 4/15\n","391/391 [==============================] - 76s 195ms/step - loss: 28.0472 - reconstruction_loss: 27.9353 - kl_loss: 1.6054e-04\n","Epoch 5/15\n","391/391 [==============================] - 75s 193ms/step - loss: 27.6991 - reconstruction_loss: 27.6047 - kl_loss: 8.7788e-05\n","Epoch 6/15\n","391/391 [==============================] - 76s 194ms/step - loss: 27.4830 - reconstruction_loss: 27.4354 - kl_loss: 0.0010\n","Epoch 7/15\n","391/391 [==============================] - 72s 184ms/step - loss: 27.4053 - reconstruction_loss: 27.3877 - kl_loss: 1.3458e-04\n","Epoch 8/15\n","391/391 [==============================] - 73s 187ms/step - loss: 27.3835 - reconstruction_loss: 27.3553 - kl_loss: 7.0930e-05\n","Epoch 9/15\n","391/391 [==============================] - 74s 188ms/step - loss: 27.3467 - reconstruction_loss: 27.3287 - kl_loss: 0.0075\n","Epoch 10/15\n","391/391 [==============================] - 73s 187ms/step - loss: 27.3221 - reconstruction_loss: 27.1231 - kl_loss: 0.1660\n","Epoch 11/15\n","391/391 [==============================] - 72s 184ms/step - loss: 27.2782 - reconstruction_loss: 26.9334 - kl_loss: 0.2936\n","Epoch 12/15\n","391/391 [==============================] - 70s 180ms/step - loss: 27.2072 - reconstruction_loss: 26.8271 - kl_loss: 0.3514\n","Epoch 13/15\n","391/391 [==============================] - 71s 183ms/step - loss: 27.1883 - reconstruction_loss: 26.7556 - kl_loss: 0.3906\n","Epoch 14/15\n","391/391 [==============================] - 72s 185ms/step - loss: 27.1558 - reconstruction_loss: 26.6965 - kl_loss: 0.4199\n","Epoch 15/15\n","391/391 [==============================] - 72s 184ms/step - loss: 27.1114 - reconstruction_loss: 26.6623 - kl_loss: 0.4360\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f98bd9c7990>"]},"metadata":{},"execution_count":54}],"source":["#(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","#print(x_train.shape, x_test.shape)\n","#mnist_digits = np.concatenate([x_train, x_test], axis=0)\n","#mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n","#print(mnist_digits.shape)\n","\n","movements=movements.reshape(50000,1,501)\n","\n","\n","vae = VAE(encoder, decoder)\n","vae.compile(optimizer=keras.optimizers.Adam())\n","#vae.fit(mnist_digits, epochs=30, batch_size=128)\n","vae.fit(movements, epochs=15, batch_size=128)#0.00005"]},{"cell_type":"code","source":["z_sample=np.random.uniform(0,1,size=[10000, 2])\n","x_decoded = vae.decoder.predict(z_sample)\n","print(x_decoded.shape)\n","x_decoded=x_decoded.reshape(10000,501)\n","x_decoded=input_minmax_scaler.inverse_transform(x_decoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GtqUNJ_URsl","executionInfo":{"status":"ok","timestamp":1654181671726,"user_tz":-120,"elapsed":5457,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"3a0f1bd7-5db4-40ab-82d2-53c725998d10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 1, 501)\n"]}]},{"cell_type":"code","source":["np.save(\"/content/drive/MyDrive/Colab Notebooks/scaled_movementsVAE.npy\", x_decoded)"],"metadata":{"id":"SUErqsVpV4FF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# HASTA AQUI"],"metadata":{"id":"DO6X7ay-F_QG"}},{"cell_type":"markdown","source":["# Images"],"metadata":{"id":"S-ylvOef714Q"}},{"cell_type":"code","source":["latent_dim = 2\n","\n","encoder_inputs = keras.Input(shape=(28, 28, 1))\n","x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n","x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(16, activation=\"relu\")(x)\n","z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n","z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n","z = Sampling()([z_mean, z_log_var])\n","encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n","encoder.summary()"],"metadata":{"id":"vcpj5huJ7xxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654533719248,"user_tz":-120,"elapsed":653,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"f8850684-27b1-4345-ab4b-3a43ae56ec5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 14, 14, 32)   320         ['input_5[0][0]']                \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d_4[0][0]']               \n","                                                                                                  \n"," flatten_2 (Flatten)            (None, 3136)         0           ['conv2d_5[0][0]']               \n","                                                                                                  \n"," dense_4 (Dense)                (None, 16)           50192       ['flatten_2[0][0]']              \n","                                                                                                  \n"," z_mean (Dense)                 (None, 2)            34          ['dense_4[0][0]']                \n","                                                                                                  \n"," z_log_var (Dense)              (None, 2)            34          ['dense_4[0][0]']                \n","                                                                                                  \n"," sampling_2 (Sampling)          (None, 2)            0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 69,076\n","Trainable params: 69,076\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["latent_inputs = keras.Input(shape=(latent_dim,))\n","x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n","x = layers.Reshape((7, 7, 64))(x)\n","x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n","decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n","decoder.summary()"],"metadata":{"id":"38yhntL_7xzV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654533725098,"user_tz":-120,"elapsed":601,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"4c1f5473-23aa-434c-b993-f0f7e26b0c84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 2)]               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 3136)              9408      \n","                                                                 \n"," reshape_2 (Reshape)         (None, 7, 7, 64)          0         \n","                                                                 \n"," conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       36928     \n"," ranspose)                                                       \n","                                                                 \n"," conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n"," ranspose)                                                       \n","                                                                 \n"," conv2d_transpose_8 (Conv2DT  (None, 28, 28, 1)        289       \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 65,089\n","Trainable params: 65,089\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss\"\n","        )\n","        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            reconstruction_loss = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n","                )\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }\n"],"metadata":{"id":"26UdAb5F7x11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","mnist_digits = np.concatenate([x_train, x_test], axis=0)\n","mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n","\n","vae = VAE(encoder, decoder)\n","vae.compile(optimizer=keras.optimizers.Adam())\n","vae.fit(mnist_digits, epochs=2, batch_size=128)"],"metadata":{"id":"P2iibjGA7x4K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654533980286,"user_tz":-120,"elapsed":234495,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"ef9c3ea9-64d1-4f14-b9f6-48512fced995"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","547/547 [==============================] - 119s 213ms/step - loss: 256.1670 - reconstruction_loss: 207.8076 - kl_loss: 3.4475\n","Epoch 2/2\n","547/547 [==============================] - 114s 209ms/step - loss: 179.8033 - reconstruction_loss: 170.6013 - kl_loss: 5.3639\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc664b80750>"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"FpKL_EiD5MWO"},"source":["## Display a grid of sampled digits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fk0XVQ605MWO","colab":{"base_uri":"https://localhost:8080/","height":849},"executionInfo":{"status":"error","timestamp":1654534179108,"user_tz":-120,"elapsed":2920,"user":{"displayName":"RSAIT RSAIT","userId":"03925996989683314338"}},"outputId":"fad92754-feeb-4526-c363-f28092fd64ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-1.         -0.93103448 -0.86206897 -0.79310345 -0.72413793 -0.65517241\n"," -0.5862069  -0.51724138 -0.44827586 -0.37931034 -0.31034483 -0.24137931\n"," -0.17241379 -0.10344828 -0.03448276  0.03448276  0.10344828  0.17241379\n","  0.24137931  0.31034483  0.37931034  0.44827586  0.51724138  0.5862069\n","  0.65517241  0.72413793  0.79310345  0.86206897  0.93103448  1.        ]\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n","(28, 28, 1)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-4c9ed81cef1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mplot_latent_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-4c9ed81cef1f>\u001b[0m in \u001b[0;36mplot_latent_space\u001b[0;34m(vae, n, figsize)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mz_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mx_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_decoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mdigit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_decoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1959\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, count, name)\u001b[0m\n\u001b[1;32m   1382\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m     \"\"\"\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mRepeatDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, count, name)\u001b[0m\n\u001b[1;32m   4694\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4695\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4696\u001b[0;31m         **self._common_args)\n\u001b[0m\u001b[1;32m   4697\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepeatDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_common_args\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    666\u001b[0m     return {\n\u001b[1;32m    667\u001b[0m         \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     }\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_flat_shapes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShapes\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melement\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mrepresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[0;32m--> 621\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mget_flat_tensor_shapes\u001b[0;34m(element_spec)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShapes\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melement\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mrepresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m   \"\"\"\n\u001b[0;32m--> 296\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_flat_tensor_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mget_flat_tensor_specs\u001b[0;34m(element_spec)\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m   return functools.reduce(lambda state, value: state + value._flat_tensor_specs,\n\u001b[0;32m--> 283\u001b[0;31m                           nest.flatten(element_spec), [])\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(state, value)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   return functools.reduce(lambda state, value: state + value._flat_tensor_specs,\n\u001b[0m\u001b[1;32m    283\u001b[0m                           nest.flatten(element_spec), [])\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_latent_space(vae, n=30, figsize=15):\n","    # display a n*n 2D manifold of digits\n","    digit_size = 28\n","    scale = 1.0\n","    figure = np.zeros((digit_size * n, digit_size * n))\n","    # linearly spaced coordinates corresponding to the 2D plot\n","    # of digit classes in the latent space\n","    grid_x = np.linspace(-scale, scale, n)\n","    grid_y = np.linspace(-scale, scale, n)[::-1]\n","\n","    for i, yi in enumerate(grid_y):\n","        for j, xi in enumerate(grid_x):\n","            z_sample = np.array([[xi, yi]])\n","            x_decoded = vae.decoder.predict(z_sample)\n","            digit = x_decoded[0].reshape(digit_size, digit_size)\n","            figure[\n","                i * digit_size : (i + 1) * digit_size,\n","                j * digit_size : (j + 1) * digit_size,\n","            ] = digit\n","\n","    plt.figure(figsize=(figsize, figsize))\n","    start_range = digit_size // 2\n","    end_range = n * digit_size + start_range\n","    pixel_range = np.arange(start_range, end_range, digit_size)\n","    sample_range_x = np.round(grid_x, 1)\n","    sample_range_y = np.round(grid_y, 1)\n","    plt.xticks(pixel_range, sample_range_x)\n","    plt.yticks(pixel_range, sample_range_y)\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.imshow(figure, cmap=\"Greys_r\")\n","    plt.show()\n","\n","\n","plot_latent_space(vae)"]},{"cell_type":"markdown","metadata":{"id":"SuYu5tpH5MWO"},"source":["## Display how the latent space clusters different digit classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUu99rDH5MWP"},"outputs":[],"source":["\n","def plot_label_clusters(vae, data, labels):\n","    # display a 2D plot of the digit classes in the latent space\n","    z_mean, _, _ = vae.encoder.predict(data)\n","    plt.figure(figsize=(12, 10))\n","    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n","    plt.colorbar()\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.show()\n","\n","\n","(x_train, y_train), _ = keras.datasets.mnist.load_data()\n","x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n","\n","plot_label_clusters(vae, x_train, y_train)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb","timestamp":1654097500120}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}